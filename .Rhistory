summary(fit5, fit.measures = T, standardized = T)
#model5
model5 <- 'level: 1
score ~ stress
stress =~  mean_heart + set_number + shoot_order + countdown + arrows
level: 2
score ~ age + female + worldranking + rankinground_rank
'
fit5 <- sem(model = model5, data = mean_dat, estimator = "ML", missing = "fiml", cluster = "match_name_id")
fit5 <- sem(model = model5, data = mean_dat, estimator = "ML", missing = "fiml", cluster = "match_name_id")
summary(fit5, fit.measures = T, standardized = T)
#model5
model5 <- 'level: 1
score ~ mean_heart
mean_heart ~ set_number + shoot_order + countdown + arrows
level: 2
score ~ age + female + worldranking + rankinground_rank
'
fit5 <- sem(model = model5, data = mean_dat, estimator = "ML", missing = "fiml", cluster = "match_name_id")
summary(fit5, fit.measures = T, standardized = T)
summary(fit4, fit.measures = T, standardized = T)
#model4
model4 <- 'level: 1
score ~ mean_heart + shoot_order + countdown + arrows
level: 2
score ~ mean_heart + stage + set_number + age + female + worldranking + rankinground_rank
'
fit4 <- sem(model = model4, data = mean_dat, estimator = "ML", missing = "fiml", cluster = "match_name_id")
summary(fit4, fit.measures = T, standardized = T)
#model4
model4 <- 'level: 1
score ~ mean_heart + shoot_order + countdown + arrows
level: 2
score ~ mean_heart + stage + set_number + age + female + worldranking + rankinground_rank
'
fit4 <- sem(model = model4, data = mean_dat, estimator = "ML", missing = "fiml", cluster = "match_name_id")
summary(fit4, fit.measures = T, standardized = T)
#model4
model4 <- 'level: 1
score ~ mean_heart + shoot_order + countdown + arrows
level: 2
score ~ mean_heart + stage + set_number + age + female + worldranking + rankinground_rank
'
fit4 <- sem(model = model4, data = mean_dat, estimator = "ML", missing = "fiml", cluster = "match_name_id")
#Heart Rate and Performance
library(tidyverse)
library(psych)
library(lavaan)
#model4
model4 <- 'level: 1
score ~ mean_heart + shoot_order + countdown + arrows
level: 2
score ~ mean_heart + stage + set_number + age + female + worldranking + rankinground_rank
'
fit4 <- sem(model = model4, data = mean_dat, estimator = "ML", missing = "fiml", cluster = "match_name_id")
summary(fit4, fit.measures = T, standardized = T)
#model6
model6 <- 'level: 1
score ~ mean_heart + shoot_order + countdown + arrows
level: 2
score ~ mean_heart + stage + set_number + age + female + worldranking + rankinground_rank
'
fit6 <- sem(model = model6, data = mean_dat, estimator = "ML", missing = "fiml", cluster = "match_name_id")
summary(fit6, fit.measures = T, standardized = T)
#model6
model6 <- 'level: 1
score ~ mean_heart + shoot_order + countdown + arrows
level: 2
score ~ stage + set_number + age + female + worldranking + rankinground_rank
'
fit6 <- sem(model = model6, data = mean_dat, estimator = "ML", missing = "fiml", cluster = "match_name_id")
#model6
model6 <- 'level: 1
score ~ mean_heart + set_number + shoot_order + countdown + arrows
level: 2
score ~ stage + age + female + worldranking + rankinground_rank
'
fit6 <- sem(model = model6, data = mean_dat, estimator = "ML", missing = "fiml", cluster = "match_name_id")
summary(fit6, fit.measures = T, standardized = T)
summary(fit5, fit.measures = T, standardized = T)
#disaster and relationship
library(haven)
getwd()
disaster = read_dta("scales_datafile_rev.dta")
write.csv(disater, file = "scales_datafile_rev.csv")
write.csv(disaster, file = "scales_datafile_rev.csv")
disaster2 = read_dta("scales_datafile_v3long_rev.dta")
write.csv(disaster2, file="scales_datafile_v3long_rev.csv")
#Heart Rate and Performance
library(tidyverse)
library(psych)
library(lavaan)
org_dat = read.csv("archery_data.csv")
org_dat = read_csv("archery_data.csv")
edit(org_dat)
edit(mean_dat)
#model5
model5 <- 'level: 1
score ~ mean_heart
mean_heart ~ set_number + shoot_order + countdown + arrows
level: 2
score ~ age + female + worldranking + rankinground_rank
'
summary(fit5, fit.measures = T, standardized = T)
fit5_1 <- sem(model = model5, data = mean_dat, cluster = "match_name_id")
summary(fit5_1, fit.measures = T, standardized = T)
##let's create time variables##
library(tidyverse)
library(lavaan)
library(psych)
library(psych)
hurri <- read_csv("scales_datafile_rev.csv")
head(hurri)
View(hurri)
# 결측치 개수
times = c(hrelsat5, hrelsat6, hrelsat7)
# 결측치 개수
times <- c("hrelsat5", "hrelsat6", "hrelsat7")
times
sum(is.na(data$times))
sum(is.na(hurri$times))
sum(is.na(times))
sum(is.na(hurri$times))
colsum(is.na(hurri$times))
colsums(is.na(hurri$times))
colSums(is.na(hurri$times))
# 결측치 존재하는 컬럼 찾기
colSums(is.na(hurri)) # data에 존재하는 변수별로 결측치 개수를 알려줍니다.
edit(hurri)
colSums(is.na(hurri$times))
colSums(is.na(hurri))
sum(is.na(hurri))
rowSums(is.na(hurri))
-> na_time
# 변수별 결측치
hurri %>% select(hrelsat5, hrelsat6, hrelsat7, wrelsat5, wrelsat6, wrelsat7) -> na_time
# 변수별 결측치
hurri %>%
select(hrelsat5, hrelsat6, hrelsat7, wrelsat5, wrelsat6, wrelsat7) -> na_time
-> na_time
na_time
colSums(is.na(na_time))
table(na_time)
rowSums(is.na(na_time))
sum(is.na(na_time), margin= c(1,2))
sum(is.na(na_time), margin(1,2))
edit(hurri)
na_time %>% if(rowSums(is.na(na_time))==6, summarise(count=n())) -> na
na_time %>% if_else(rowSums(is.na(na_time))==6, summarise(count=n())) -> na
na_time %>% ifelse(rowSums(is.na(na_time))==6, summarise(count=n())) -> na
na_time %>% if_else(rowSums(is.na(na_time))==6, summarise(count=n())) -> na
na_time
# 변수별 결측치
hurri %>%
select(hrelsat5, hrelsat6, hrelsat7, wrelsat5, wrelsat6, wrelsat7) %>% data.frame() -> na_time
na_time %>% if_else(rowSums(is.na(na_time))==6, summarise(count=n())) -> na
rowSums(is.na(na_time))
rowSums(is.na(na_time))==6
tf <- rowSums(is.na(na_time))==6
tf
na_time %>% if_else(tf=TRUE, summarise(count=n())) -> na
na_time %>% if_else(tf==TRUE, summarise(count=n())) -> na
na
tf
View(na_time)
na_time %>% if_else(tf==TRUE, sum(tf==TRUE) -> na
na
na_time %>% if_else(tf==TRUE, sum(tf==TRUE)) -> na
sum(tf==TRUE) -> na
na
na
hurri_na %>% filter(NN==1) %>% count()
hurri_na |> filter(NN==1) |> count()
hurri_na %>% filter(NN==1) %>% count() -> num_na
##let's create time variables##
library(tidyverse)
library(lavaan)
library(psych)
hurri_na %>% filter(NN==1) %>% count()
hurri <- read_csv("scales_datafile_rev.csv")
# 변수별 결측치
hurri %>%
select(hrelsat5, hrelsat6, hrelsat7, wrelsat5, wrelsat6, wrelsat7) %>% data.frame() -> na_time
# colSums(is.na(na_time))
NN<- rowSums(is.na(na_time))
# 위의 64쌍의 부부를 구분하는 더미변수 생성(개수만 센거라 위 데이터로 가능할지 모르겠다)
hurri %>%
mutate(NN = replace(NN, rowSums(is.na(na_time)) == 6, 1)) %>%
mutate(NN = replace(NN, rowSums(is.na(na_time)) != 6, 0))-> hurri_na #success~*^0^* replace 함수로 특정 열의 값 대체
hurri_na %>% filter(NN==1) %>% count()
#기술통계표 만들기
sums = c(hrelsat1, hrelsat2, hrelsat3, hrelsat5, hrelsat6, hrelsat7, hexposure, hps3, hsupp3, wrelsat1, wrelsat2, wrelsat3, wrelsat5, wrelsat6, wrelsat7, wexposure, wps3, wsupp3)
#기술통계표 만들기
hurri %>% c(hrelsat1, hrelsat2, hrelsat3, hrelsat5, hrelsat6, hrelsat7, hexposure, hps3, hsupp3, wrelsat1, wrelsat2, wrelsat3, wrelsat5, wrelsat6, wrelsat7, wexposure, wps3, wsupp3)
#기술통계표 만들기
hurri_na %>% c(hrelsat1, hrelsat2, hrelsat3, hrelsat5, hrelsat6, hrelsat7, hexposure, hps3, hsupp3, wrelsat1, wrelsat2, wrelsat3, wrelsat5, wrelsat6, wrelsat7, wexposure, wps3, wsupp3)
View(hurri_na)
#기술통계표 만들기
hurri_na %>% c(hrelsat1, hrelsat2, hrelsat3, hrelsat5, hrelsat6, hrelsat7, hexposure, hps3, hsupp3, wrelsat1, wrelsat2, wrelsat3, wrelsat5, wrelsat6, wrelsat7, wexposure, wps3, wsupp3)
#기술통계표 만들기기
hurri_na %>% c(hrelsat1, hrelsat2, hrelsat3, hrelsat5, hrelsat6, hrelsat7, hexposure, hps3, hsupp3, wrelsat1, wrelsat2, wrelsat3, wrelsat5, wrelsat6, wrelsat7, wexposure, wps3, wsupp3)
hurri_na$hrelsat1
#기술통계표 만들기기
hurri_na %>%
table(cur_data()[c("hrelsat1", "hrelsat2", "hrelsat3", "hrelsat5",
"hrelsat6", "hrelsat7", "hexposure", "hps3", "hsupp3",
"wrelsat1", "wrelsat2", "wrelsat3", "wrelsat5", "wrelsat6",
"wrelsat7", "wexposure", "wps3", "wsupp3")]) -> table
#기술통계표 만들기기
hurri_na %>%
table(pick()[c("hrelsat1", "hrelsat2", "hrelsat3", "hrelsat5",
"hrelsat6", "hrelsat7", "hexposure", "hps3", "hsupp3",
"wrelsat1", "wrelsat2", "wrelsat3", "wrelsat5", "wrelsat6",
"wrelsat7", "wexposure", "wps3", "wsupp3")]) -> table
#기술통계표 만들기기
hurri_na %>%
table(c("hrelsat1", "hrelsat2", "hrelsat3", "hrelsat5",
"hrelsat6", "hrelsat7", "hexposure", "hps3", "hsupp3",
"wrelsat1", "wrelsat2", "wrelsat3", "wrelsat5", "wrelsat6",
"wrelsat7", "wexposure", "wps3", "wsupp3")) -> table
#기술통계표 만들기기
hurri_na %>%
table(select("hrelsat1", "hrelsat2", "hrelsat3", "hrelsat5",
"hrelsat6", "hrelsat7", "hexposure", "hps3", "hsupp3",
"wrelsat1", "wrelsat2", "wrelsat3", "wrelsat5", "wrelsat6",
"wrelsat7", "wexposure", "wps3", "wsupp3")) -> table
#기술통계표 만들기기
hurri_na %>%
select(hrelsat1, hrelsat2, hrelsat3, hrelsat5,
hrelsat6, hrelsat7, hexposure, hps3, hsupp3,
wrelsat1, wrelsat2, wrelsat3, wrelsat5, wrelsat6,
wrelsat7, wexposure, wps3, wsupp3) -> table
table
#기술통계표 만들기기
hurri_na %>%
select(hrelsat1, hrelsat2, hrelsat3, hrelsat5,
hrelsat6, hrelsat7, hexposure, hps3, hsupp3,
wrelsat1, wrelsat2, wrelsat3, wrelsat5, wrelsat6,
wrelsat7, wexposure, wps3, wsupp3) %>% table() -> table
#기술통계표 만들기
dput(head(hurri_na))
str(hurri_na)
hurri_na %>%
select(hrelsat1, hrelsat2, hrelsat3, hrelsat5,
hrelsat6, hrelsat7, hexposure, hps3, hsupp3,
wrelsat1, wrelsat2, wrelsat3, wrelsat5, wrelsat6,
wrelsat7, wexposure, wps3, wsupp3) %>% table() -> table
hurri_na %>%
select(hrelsat1, hrelsat2, hrelsat3, hrelsat5,
hrelsat6, hrelsat7, hexposure, hps3, hsupp3) %>% table() -> table
hurri_na %>%
select(hrelsat1, hrelsat2, hrelsat3, hrelsat5,
hrelsat6, hrelsat7) %>% table() -> table
hurri_na %>%
select(hrelsat1, hrelsat2, hrelsat3, hrelsat5) %>% table() -> table
table
hurri_na %>%
select(hrelsat1, hrelsat2, hrelsat3, hrelsat5,
hrelsat6, hrelsat7, hexposure, hps3, hsupp3) %>% mean() -> table
hurri_na %>%
select(hrelsat1, hrelsat2, hrelsat3, hrelsat5,
hrelsat6, hrelsat7, hexposure, hps3, hsupp3) %>% mean() -> table
mean(hurri_na)
mean(hurri_na, na=T)
mean(hurri_na, na="NA")
summary(hurri_na)
hurri <- read_csv("scales_datafile_rev.csv")
# 변수별 결측치
hurri %>%
select(hrelsat5, hrelsat6, hrelsat7, wrelsat5, wrelsat6, wrelsat7) %>% data.frame() -> na_time
# 위의 64쌍의 부부를 구분하는 더미변수 생성(개수만 센거라 위 데이터로 가능할지 모르겠다)
hurri %>%
mutate(NN = replace(NN, rowSums(is.na(na_time)) == 6, 1)) %>%
mutate(NN = replace(NN, rowSums(is.na(na_time)) != 6, 0))-> hurri_na #success~*^0^* replace 함수로 특정 열의 값 대체
hurri_na %>% filter(NN==1) %>% count()
# colSums(is.na(na_time))
NN<- rowSums(is.na(na_time))
# 위의 64쌍의 부부를 구분하는 더미변수 생성(개수만 센거라 위 데이터로 가능할지 모르겠다)
hurri %>%
mutate(NN = replace(NN, rowSums(is.na(na_time)) == 6, 1)) %>%
mutate(NN = replace(NN, rowSums(is.na(na_time)) != 6, 0))-> hurri_na #success~*^0^* replace 함수로 특정 열의 값 대체
hurri_na %>% filter(NN==1) %>% count()
#기술통계
hurri_na %>% select(hrelsat1, hrelsat2, hrelsat3, hrelsat5, hrelsat6, hrelsat7, hexposure, hps3, hsupp3,
wrelsat1, wrelsat2, wrelsat3, wrelsat5, wrelsat6, wrelsat7, wexposure, wps3, wsupp3) %>%
summary() -> summar
summar
triad <- read.spss("Study 4 - LTO and Indulgence International.sav", to.data.frame=T)
require(foreign)
library(fmsb)
require(lattice)
require(MASS)
require(lme4)
require(lmerTest)
require(MuMIn)
require(car)
triad <- read.spss("~/Documents/Psychology/Research/Iran Dry versus Rainy Regions/Dry vs Rainy Open Data/Study 4 - LTO and Indulgence International.sav", to.data.frame=T)
triad <- read.spss("Study 4 - LTO and Indulgence International.sav", to.data.frame=T)
triad <- read.spss("Study 4 - LTO and Indulgence International.sav", to.data.frame=T)
edit(triad)
write.csv(triad, file="triad")
library(tidyverse);library(psych);library(tidyr);library(sem)
wisdom <- read_csv("HainesEtAI_data.csv")
wisdom <- read_csv("HainesEtAl_data.csv")
head(wisdom)
edit(wisdom)
as.data.frame(wisdom)
edit(wisdom)
edit.data.frame(wisdom)
edit(as.data.frame(wisdom))
View(wisdom)
head(wisdom)
wisdom %>% select(SEMA_ID, Time, CTRLcln, REAP, REAP_1, ZDASS_D, ZDASS_A,
SDAsSS_S, ZRSE, ZSOCANX, TRRL_M) -> main_wis
wisdom %>% select(SEMA_ID, Time, CTRLcln, REAP, REAP_1, ZDASS_D, ZDASS_A,
SDASS_S, ZRSE, ZSOCANX, TRRL_M) -> main_wis
wisdom %>% select(SEMA_ID, Time, CTRLcln, REAP, REAP_1, ZDASS_D, ZDASS_A,
ZDASS_S, ZRSE, ZSOCANX, TRRL_M) -> main_wis
wisdom %>% select(SEMA_ID, Time, CTRLcln, REAP, REAP_1, ZDASS_D, ZDASS_A,
ZDASS_S, ZRSE, ZSOCANX, CTRL_M) -> main_wis
edit(main_wis)
edit(main_wis)
lmmod_D <- 'level1:
REAP ~ a + p1*CTRLcln + p2*Time + p3*REAP_1
level2:
a ~ b00 + b01*ZDASS_D + b02*CTRL_M
p1 ~ b10 + b11*ZDASS_D + b12*CTRL_M
p2 ~ b20 + b21*ZDASS_D + b22*CTRL_M
p3 ~ b30 + b31*ZDASS_D + b32*CTRL_M'
lm_D <- sem(model = lmmod_D, data = main_wis, cluster = "SEMA_ID")
lmmod_D <- 'level: 1
REAP ~ a + p1*CTRLcln + p2*Time + p3*REAP_1
level: 2
a ~ b00 + b01*ZDASS_D + b02*CTRL_M
p1 ~ b10 + b11*ZDASS_D + b12*CTRL_M
p2 ~ b20 + b21*ZDASS_D + b22*CTRL_M
p3 ~ b30 + b31*ZDASS_D + b32*CTRL_M'
lm_D <- sem(model = lmmod_D, data = main_wis, cluster = "SEMA_ID")
lmmod_D <- '
level: 1
REAP ~ a + p1*CTRLcln + p2*Time + p3*REAP_1
level: 2
a ~ b00 + b1*ZDASS_D + b2*CTRL_M
p1 ~ b10 + c1*ZDASS_D + c2*CTRL_M
p2 ~ b20 + d1*ZDASS_D + d2*CTRL_M
p3 ~ b30 + e1*ZDASS_D + e2*CTRL_M'
lm_D <- sem(model = lmmod_D, data = main_wis, cluster = "SEMA_ID")
main_wis
is.matrix(lmmod_D)
summary(lm_D)
library(lavaan)
lmmod_D <- '
level: 1
REAP ~ a + p1*CTRLcln + p2*Time + p3*REAP_1
level: 2
a ~ b00 + b1*ZDASS_D + b2*CTRL_M
p1 ~ b10 + c1*ZDASS_D + c2*CTRL_M
p2 ~ b20 + d1*ZDASS_D + d2*CTRL_M
p3 ~ b30 + e1*ZDASS_D + e2*CTRL_M'
lm_D <- sem(model = lmmod_D, data = main_wis, cluster = "SEMA_ID")
lmmod_D <- '
level: 1
REAP ~ 1 + p1*CTRLcln + p2*Time + p3*REAP_1
level: 2
1 ~ b00 + b1*ZDASS_D + b2*CTRL_M
CTRLcln ~ b10 + c1*ZDASS_D + c2*CTRL_M
Time ~ b20 + d1*ZDASS_D + d2*CTRL_M
REAP_1 ~ b30 + e1*ZDASS_D + e2*CTRL_M'
lm_D <- sem(model = lmmod_D, data = main_wis, cluster = "SEMA_ID")
lmmod_D <- '
level: 1
REAP ~ 1 + p1*CTRLcln + p2*Time + p3*REAP_1
level: 2
REAP ~ b00 + b1*ZDASS_D + b2*CTRL_M
CTRLcln ~ b10 + c1*ZDASS_D + c2*CTRL_M
Time ~ b20 + d1*ZDASS_D + d2*CTRL_M
REAP_1 ~ b30 + e1*ZDASS_D + e2*CTRL_M'
lm_D <- sem(model = lmmod_D, data = main_wis, cluster = "SEMA_ID")
summary(lm_D)
lmmod_D <- '
level: 1
REAP ~ 1 + p1*CTRLcln + p2*Time + p3*REAP_1
level: 2
REAP ~ 1 + ZDASS_D + CTRL_M
CTRLcln ~ 1 + ZDASS_D + CTRL_M
Time ~ 1 + ZDASS_D + CTRL_M
REAP_1 ~ 1 + ZDASS_D + CTRL_M'
lm_D <- sem(model = lmmod_D, data = main_wis, cluster = "SEMA_ID")
summary(lm_D)
lm_D <- sem(model = lmmod_D, data = main_wis, cluster = "SEMA_ID", verbose = T, optim.method = "em")
lm_D <- sem(model = lmmod_D, data = main_wis, cluster = "SEMA_ID", verbose = T,
optim.method = "em", em.iter.max = 10000, em.fx.tol = 1e-08, em.dx.tol = 1e-04)
#lmer package로 해보기
library(lmerTest)
intercept.only.model <- lmer(REAP ~ 1 + ( 1 + Days | Subject), data=main_wis)
library(lavaan)
intercept.only.model <- lmer(REAP ~ 1 + ( 1 + Days | Subject), data=main_wis)
#lmer package로 해보기
library(nlme)
intercept.only.model <- lmer(REAP ~ 1 + ( 1 + Days | Subject), data=main_wis)
library(lme4)
intercept.only.model <- lmer(REAP ~ 1 + ( 1 + Days | Subject), data=main_wis)
intercept.only.model <- lmer(REAP ~ 1 + ( 1 | SEMA_ID), data=main_wis)
summary(intercept.only.model)
edit(main_wis)
l
summary(intercept.only.model)
wisdom %>% select(SEMA_ID, Time, CTRLcln, REAP, REAP_1, ZBFI_N, ZDASS_D, ZDASS_A,
ZDASS_S, ZRSE, ZSOCANX, CTRL_M) -> main_wis
str(main_wis)
intercept.only.model <- lmer(REAP ~ 1 + ( 1 | SEMA_ID), data=main_wis)
summary(intercept.only.model)
ranef(intercept.only.model)
intercept.only.model[2,1]
ICCs = 285.5/(285.5 + 341.0)
ICCs
(ICCs = 285.5/(285.5 + 341.0))
ranova(intercept.only.model) #significance test for the intercept variance, ccompared with null model
lmerTest(intercept.only.model) #significance test for the intercept variance, ccompared with null model
ranova(intercept.only.model) #significance test for the intercept variance, ccompared with null model
?ranova
??ranova
??lmerTest
?lmerTest
library(anova)
library(ranova)
library(lmerTest)
install.packages("lmerTest")
library(lmerTest)
lmerTest(intercept.only.model) #significance test for the intercept variance, ccompared with null model
ranova(intercept.only.model) #significance test for the intercept variance, ccompared with null model
FALSE `geom_smooth()` using formula 'y ~ x'
library(ggplot2)
FALSE `geom_smooth()` using formula 'y ~ x'
FALSE `geom_smooth()` using formula 'REAP ~ 1'
`geom_smooth()` using formula 'REAP ~ 1'
install.packages("gridExtra")
library(gridExtra)
FALSE `geom_smooth()` using formula 'y ~ x'
library(gridExtra)
FALSE `geom_smooth()` using formula 'y ~ x'
main_wis %>% ggplot(x=Time, y=REAP, group=SEMA_ID, lty=group) +
geom_point() + geom_smooth(formula = y ~ x, "loess") -> intercept.only
main_wis %>% ggplot(x=Time, y=REAP, group=SEMA_ID, lty=group) +
geom_point() + geom_smooth(aes(formula = y ~ x), "loess") -> intercept.only
main_wis %>% ggplot(x=Time, y=REAP, group=SEMA_ID) +
geom_point() + geom_smooth(aes(formula = y ~ x), "loess") -> intercept.only
main_wis %>% ggplot(x=Time, y=REAP, group=SEMA_ID) +
geom_point() -> intercept.only
intercept.only
main_wis %>% ggplot(x=Time, y=REAP, group=SEMA_ID) +
geom_point(group=SEMA_ID) -> intercept.only
main_wis %>% ggplot(x=Time, y=REAP, group=SEMA_ID) +
geom_point(group="SEMA_ID") -> intercept.only
intercept.only
main_wis %>% ggplot(x=Time, y=REAP, group="SEMA_ID") +
geom_point(colours()) -> intercept.only
main_wis %>% ggplot(x=Time, y=REAP, group="SEMA_ID") +
geom_point() -> intercept.only
intercept.only
# FALSE `geom_smooth()` using formula 'y ~ x' #plot..?
random.intercept.model <- lmer(REAP ~ ZDASS_D + (1 | SEMA_ID), data = main_wis)
summary(random.intercept.model)
# FALSE `geom_smooth()` using formula 'y ~ x' #plot..?
random.intercept.model <- lmer(REAP ~ CTRLcln + (1 | SEMA_ID), data = main_wis)
summary(random.intercept.model)
# FALSE `geom_smooth()` using formula 'y ~ x' #plot..?
random.intercept.model <- lmer(REAP ~ REAP_1 + (1 | SEMA_ID), data = main_wis)
summary(random.intercept.model)
ranef(random.intercept.model) #each regression for ID
summary(intercept.only.model)
summary(random.intercept.model)
(explained <- (341.0 - 322.9)/341.0)
(explained_T <- ((285.5 + 341.0)-(172.5+322.9)/(285.5 + 341.0)))
(explained_T <- ((285.5 + 341.0)-(172.5+322.9))/(285.5 + 341.0)))
(explained_T <- ((285.5 + 341.0)-(172.5+322.9))/(285.5 + 341.0))
##3
Q3 <- read.table("HW1data/data1.txt", head = T, na.strings = ".")
Q3
##3
Q3 <- read.table("HW1data/data1.txt", head = T, na.strings = ".")
#두 상관계수의 차이검증
(a=r.test(n=62, r12= .15, r34 = .64))
print(a, digits = 3)
Q2_f
library(tidyverse);library(psych);library(tidyr);library(ggplot2)
Q1 <- read_csv("HW1data/minitest.csv")
# FALSE `geom_smooth()` using formula 'y ~ x' #plot..?
random.intercept.model <- lmer(REAP ~ CTRLcln + Time + REAP_1 + (1 | SEMA_ID), data = main_wis)
summary(random.intercept.model)
(explained_lv1 <- (341.0 - 323.1)/341.0) #explained level1 variance
(explained_T <- ((285.5 + 341.0)-(173.7+323.1))/(285.5 + 341.0)) #explained total variance
View(lm_D)
random.coefficients.model <- lmer(REAP ~ CTRLcln + Time + REAP_1 +(ZDASS_D + CTRL_M | SEMA_ID), data = main_wis)
summary(random.coefficients.model)
ranef(random.coefficients.model)
random.coefficients.model <- lmer(REAP ~ CTRLcln + Time + REAP_1 +(ZDASS_D + CTRL_M | SEMA_ID), data = main_wis, REML = T)
main_wis$random.coefficients.reds <- predict(random.coefficients.model)
main_wis$random.coefficients.preds <- predict(random.coefficients.model)
random.coefficients.preds <- predict(random.coefficients.model)
summary(random.coefficients.model)
random.coefficients.model <- lmer(REAP ~ CTRLcln + Time + REAP_1 +(CTRLcln + Time + REAP_1| SEMA_ID), data = main_wis, REML = T)
context.model <- lmer(REAP ~ CTRLcln + Time + REAP_1 + CTRL_M +(1 | SEMA_ID), data = main_wis, REML = T)
summary(random.coefficients.model)
context.model <- lmer(REAP ~ CTRLcln + Time + REAP_1 + CTRL_M + ZDASS_D +(1 | SEMA_ID), data = main_wis, REML = T)
random.coefficients.preds <- predict(random.coefficients.model)
summary(random.coefficients.model)
context.model <- lmer(REAP ~ CTRLcln + Time + REAP_1 + CTRL_M + ZDASS_D +(1 | SEMA_ID), data = main_wis, REML = T)
summary(random.coefficients.model)
summary(context.model)
context.model <- lmer(REAP ~ CTRLcln + Time + REAP_1 + CTRL_M + ZDASS_D +( CTRLcln + Time + REAP_1 | SEMA_ID), data = main_wis, REML = T)
summary(context.model)
